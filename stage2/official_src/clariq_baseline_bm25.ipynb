{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "name": "ClariQ_Baseline_BM25",
   "provenance": [],
   "collapsed_sections": [],
   "toc_visible": true
  },
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/moli/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/moli/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rank_bm25 import BM25Okapi\n",
    "import nltk\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "def stem_tokenize(text, remove_stopwords=True):\n",
    "  stemmer = PorterStemmer()\n",
    "  tokens = [word for sent in nltk.sent_tokenize(text) \\\n",
    "                                      for word in nltk.word_tokenize(sent)]\n",
    "  tokens = [word for word in tokens if word not in \\\n",
    "          nltk.corpus.stopwords.words('english')]\n",
    "  return [stemmer.stem(word) for word in tokens]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# Files paths\n",
    "\n",
    "request_file_path = '../data/dev.tsv'\n",
    "question_bank_path = '../data/question_bank.tsv'\n",
    "run_file_path = '../sample_runs/dev_bm25'"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "M13NOK7Kytuv",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "outputId": "ded6d015-5413-41b0-ec24-ed91c9440a98"
   },
   "source": [
    "# Reads files and build bm25 corpus (index)\n",
    "\n",
    "dev = pd.read_csv(request_file_path, sep='\\t')\n",
    "question_bank = pd.read_csv(question_bank_path, sep='\\t').fillna('')\n",
    "\n",
    "question_bank['tokenized_question_list'] = question_bank['question'].map(stem_tokenize)\n",
    "question_bank['tokenized_question_str'] = question_bank['tokenized_question_list'].map(lambda x: ' '.join(x))\n",
    "\n",
    "bm25_corpus = question_bank['tokenized_question_list'].tolist()\n",
    "bm25 = BM25Okapi(bm25_corpus)"
   ],
   "execution_count": 25,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "mG4IWxSfytpT",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    "# Runs bm25 for every query and stores output in file.\n",
    "\n",
    "with open(run_file_path, 'w') as fo:\n",
    "  for tid in dev['topic_id'].unique():\n",
    "    query = dev.loc[dev['topic_id']==tid, 'initial_request'].tolist()[0]\n",
    "    bm25_ranked_list = bm25.get_top_n(stem_tokenize(query, True), \n",
    "                                    bm25_corpus, \n",
    "                                    n=30)\n",
    "    bm25_q_list = [' '.join(sent) for sent in bm25_ranked_list]\n",
    "    preds = question_bank.set_index('tokenized_question_str').loc[bm25_q_list, 'question_id'].tolist()\n",
    "    for i, qid in enumerate(preds):    \n",
    "      fo.write('{} 0 {} {} {} bm25\\n'.format(tid, qid, i, len(preds)-i))"
   ],
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "w7hTtiHyQW1_",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 84
    },
    "outputId": "5b4dae48-1575-4179-d2e8-3a4ceaf7e859"
   },
   "source": [
    "# Report question relevance performance\n",
    "! python clariq_eval_tool.py    --eval_task question_relevance\\\n",
    "                                --data_dir ../data/ \\\n",
    "                                --experiment_type dev \\\n",
    "                                --run_file {run_file_path} \\\n",
    "                                --out_file {run_file_path}_question_relevance.eval"
   ],
   "execution_count": 29,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall5: 0.3245570421150917\r\n",
      "Recall10: 0.5638042646208281\r\n",
      "Recall20: 0.6674997108155003\r\n",
      "Recall30: 0.6912818698329535\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "hh-2P1kJ5Gp2",
    "colab_type": "code",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 202
    },
    "outputId": "66540c57-be2d-46f6-a9cc-e44d95d2fbad"
   },
   "source": [
    "! python clariq_eval_tool.py    --eval_task document_relevance\\\n",
    "                                --data_dir ../data/ \\\n",
    "                                --experiment_type dev \\\n",
    "                                --run_file {run_file_path} \\\n",
    "                                --out_file {run_file_path}.eval"
   ],
   "execution_count": 30,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NDCG1: 0.1859375\r\n",
      "NDCG3: 0.16076878817226317\r\n",
      "NDCG5: 0.15299655291242895\r\n",
      "NDCG10: 0.1362843190319216\r\n",
      "NDCG20: 0.12845266881072878\r\n",
      "P1: 0.23125\r\n",
      "P3: 0.18958333333333333\r\n",
      "P5: 0.17500000000000002\r\n",
      "P10: 0.140625\r\n",
      "P20: 0.11812500000000001\r\n",
      "MRR100: 0.30959228090067364\r\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "29kHe2dQ5JWV",
    "colab_type": "code",
    "colab": {}
   },
   "source": [
    ""
   ],
   "execution_count": 28,
   "outputs": []
  }
 ]
}